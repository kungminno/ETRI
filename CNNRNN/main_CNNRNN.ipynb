{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1677217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, LSTM, Dense, Reshape ,Dropout, Flatten\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from keras import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce0a268",
   "metadata": {},
   "source": [
    "<span style='background-color:#fff5b1'>data_dir는 사용자에 맞게 변경 필요</span>\n",
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e54080",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:/Users/kungm/Desktop/ETRI/example/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05780824",
   "metadata": {},
   "source": [
    "Model: CNN + RNN\n",
    "============\n",
    " - CNN(ResNet50)\n",
    " - RNN(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7a1bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    #cnn\n",
    "    inp = Input(shape=(224,224,3)) # (channels,height,width)\n",
    "    #include_top=False는 가장 상단의 fully connected계층들을 포함 시키지 않음\n",
    "    resnet = ResNet50(input_tensor=inp, include_top=False, weights='imagenet', pooling='avg')\n",
    "    resnet_output = resnet.output\n",
    "\n",
    "    #Fitting 문제 방지\n",
    "    resnet_batch_norm = BatchNormalization(axis=1)(resnet_output)\n",
    "    \n",
    "    #lstm 입층력 층에 맞추기 위해 reshape\n",
    "    lstm_input = Reshape((1, 2048))(resnet_batch_norm)\n",
    "    \n",
    "    #lstm\n",
    "    lstm0 = LSTM(64,activation='relu',return_sequences=True)(lstm_input)\n",
    "    lstm_batch_norm0 = BatchNormalization(axis=1)(lstm0)\n",
    "\n",
    "    lstm1 = LSTM(32,activation='relu',return_sequences=True)(lstm_batch_norm0)\n",
    "    lstm_batch_norm1 = BatchNormalization(axis=1)(lstm1)\n",
    "\n",
    "    lstm2 = LSTM(16,activation='relu',return_sequences=True)(lstm_batch_norm1)\n",
    "\n",
    "\n",
    "    #no matching domension issue 해결 위함\n",
    "    lstm_f = Flatten()(lstm2)\n",
    "    dense = Dense(16, activation='relu')(lstm_f)\n",
    "    batch = BatchNormalization(axis=1)(dense)\n",
    "    dropout = Dropout(0.3)(batch)\n",
    "    output= Dense(7, activation='softmax')(dropout)\n",
    "    \n",
    "    CNN_RNN = Model(inputs = inp, outputs = output)\n",
    "    \n",
    "\n",
    "    return CNN_RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee24381d",
   "metadata": {},
   "source": [
    "Load train dataset\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65f9cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train={}\n",
    "data_train['ID']=[]\n",
    "data_train['path']=[]\n",
    "data_train['emotion']=[]\n",
    "\n",
    "\n",
    "with open(data_dir + 'train_final.pickle', 'rb') as f:\n",
    "    #파일을 열고 닫는 것을 자동으로 처리\n",
    "    data_train = pickle.load(f)\n",
    "    \n",
    "\n",
    "ds_train = pd.DataFrame.from_dict(data_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5700e7c6",
   "metadata": {},
   "source": [
    "Model training\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ea31f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    " try:\n",
    "     tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    " except RuntimeError as e:\n",
    "     print(e)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "keras.backend.clear_session()\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "\n",
    "CNN_RNN = build_model()\n",
    "\n",
    "CNN_RNN.compile(\n",
    "    optimizer = adam,\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "######################################## 5-fold 교차 검증(cross-validation) ######################################## \n",
    "\n",
    "SPLITS = 5\n",
    "skf = StratifiedKFold(n_splits = SPLITS)\n",
    "n_iter = 0\n",
    "\n",
    "features = ds_train.iloc[:,1:2]\n",
    "label = pd.DataFrame(ds_train['emotion'])\n",
    "\n",
    "score_list = []\n",
    "for train_idx, val_idx in skf.split(features, label):\n",
    "    n_iter += 1\n",
    "    print(f'--------------------{n_iter}번째 KFold-------------------')\n",
    "    print(f'train_idx_len : {len(train_idx)} / val_idx_len : {len(val_idx)}')\n",
    "\n",
    "    label_train = label.iloc[train_idx]\n",
    "    label_val = label.iloc[val_idx]\n",
    "\n",
    "    X_train, X_val = features.iloc[train_idx, :], features.iloc[val_idx, :]\n",
    "    y_train, y_val = label.iloc[train_idx,:], label.iloc[val_idx,:]\n",
    "    \n",
    "    img_train=[]\n",
    "    label_train=[]\n",
    "    img_val=[]\n",
    "    label_val=[]\n",
    "\n",
    "    for index in train_idx:\n",
    "        img = X_train['path'][index]\n",
    "        img_train.append(img)\n",
    "        emotion = y_train['emotion'][index]\n",
    "        label_train.append(emotion)\n",
    "        \n",
    "    for index in val_idx:\n",
    "        img = X_val['path'][index]\n",
    "        img_val.append(img)\n",
    "        emotion = y_val['emotion'][index]\n",
    "        label_val.append(emotion)\n",
    "        \n",
    "        \n",
    "    label_train= tf.keras.utils.to_categorical(label_train)\n",
    "    label_val= tf.keras.utils.to_categorical(label_val)  \n",
    "    \n",
    "    img_train=np.array(img_train)\n",
    "    label_train=np.array(label_train)\n",
    "    img_val=np.array(img_val)\n",
    "    label_val=np.array(label_val)\n",
    "\n",
    "\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        history = CNN_RNN.fit(\n",
    "            img_train,\n",
    "            label_train,\n",
    "            batch_size=16,\n",
    "            epochs=60, #epochs 40,50,100\n",
    "            verbose=1)\n",
    "\n",
    "    preds = CNN_RNN.predict(img_val)\n",
    "    preds_labels = np.argmax(preds, axis=1)\n",
    "    y_val_labels = np.argmax(label_val, axis=1)\n",
    "    score = accuracy_score(y_val_labels, preds_labels)\n",
    "\n",
    "    print(f'{n_iter}번째 단일 accuracy_score:{score}')\n",
    "    score_list.append(score)\n",
    "\n",
    "\n",
    "print('======================================================')\n",
    "print(f'최종 평균 accuracy_socre : {sum(score_list)/len(score_list)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9955b4ce",
   "metadata": {},
   "source": [
    "Load test dataset\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "488f40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test={}\n",
    "data_test['ID']=[]\n",
    "data_test['path']=[]\n",
    "data_test['emotion']=[]\n",
    "\n",
    "\n",
    "\n",
    "with open(data_dir + 'test_final.pickle', 'rb') as f:\n",
    "    #파일을 열고 닫는 것을 자동으로 처리\n",
    "    data_test = pickle.load(f)\n",
    "\n",
    "ds_test = pd.DataFrame.from_dict(data_test)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8bafc8",
   "metadata": {},
   "source": [
    "Predict test data\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfe2dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "# 위의 모델 학습을 돌리지 않고, 완성된 모델을 가져와 predict test data\n",
    "CNN_RNN = load_model(data_dir + 'CNN_RNN_fold_epoch60_e4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0742b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_test=[]\n",
    "label_test=[]\n",
    "\n",
    "\n",
    "        \n",
    "for i in range(len(data_test['path'])):\n",
    "    feature = data_test['path'][i]\n",
    "    feature_test.append(feature)\n",
    "    emotion = data_test['emotion'][i]\n",
    "    label_test.append(emotion)\n",
    "    \n",
    "label_test= tf.keras.utils.to_categorical(label_test)\n",
    "\n",
    "feature_test=np.array(feature_test)\n",
    "label_test=np.array(label_test)\n",
    "\n",
    "\n",
    "y_test  = label_test\n",
    "y_preds_test = CNN_RNN.predict(feature_test)\n",
    "print('test', roc_auc_score(y_test[:len(y_preds_test)], y_preds_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etri",
   "language": "python",
   "name": "etri"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
