{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2775fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import collections\n",
    "import json\n",
    "import numpy as np\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79627f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_extraction(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # Extract the columns of interest and drop the first row\n",
    "    eval_df = df[['Segment ID', 'Total Evaluation']].drop([0], axis=0)\n",
    "\n",
    "    # Remove rows with multiple evaluations and apply filters based on the filename\n",
    "    segment_id = filepath[-9:-8]\n",
    "    eval_df = eval_df[~eval_df['Segment ID'].str.contains(segment_id)]\n",
    "    eval_df = eval_df[~eval_df['Total Evaluation'].str.contains(';')] # remove duplicate evaluations\n",
    "    \n",
    "    # Reset the index and shuffle the rows\n",
    "    eval_df.reset_index(drop=True, inplace=True)\n",
    "    indices = np.arange(len(eval_df))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    return eval_df, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84339c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_file_content(file_content):\n",
    "    \"\"\"\n",
    "    파일 내용에서 불필요한 문자를 제거하고 다중 공백을 제거한 문자열을 반환합니다.\n",
    "\n",
    "    Args:\n",
    "        file_content (str): 파일 내용\n",
    "\n",
    "    Returns:\n",
    "        str: 불필요한 문자와 다중 공백이 제거된 문자열\n",
    "    \"\"\"\n",
    "    unwanted_chars = 'c/n/N/u/l/b/s/o/*+/()\\\"'\n",
    "    for char in unwanted_chars:\n",
    "        file_content = file_content.replace(char, '')\n",
    "\n",
    "    file_content = re.sub(' +', ' ', file_content)\n",
    "\n",
    "    return file_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b91bcea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_emotion(dataframe, dictionary, idx_array):\n",
    "    for i in idx_array:\n",
    "        segment_id = dataframe.iloc[i, 0]\n",
    "        total_eval = dataframe.iloc[i, 1]\n",
    "        \n",
    "        PATH = f\"./KEMDy19/wav/Session{segment_id[4:6]}/{segment_id[:-5]}/{segment_id}\"\n",
    "        text_path = PATH + \".txt\"\n",
    "        wav_path = PATH + \".wav\"\n",
    "        \n",
    "        # 파일이 존재하지 않으면 건너뜀\n",
    "        if not os.path.exists(text_path):\n",
    "            continue\n",
    "            \n",
    "        with open(text_path, 'r', encoding='utf-8') as file:\n",
    "            file_content = file.read() \n",
    "            file_content = clean_file_content(file_content)\n",
    "            \n",
    "        # 감정 레이블에 따라 dictionary에 저장\n",
    "        emotions = ['fear', 'surprise', 'angry', 'sad', 'neutral', 'happy', 'disgust']\n",
    "        if total_eval in emotions:\n",
    "            label = emotions.index(total_eval)\n",
    "            dictionary[segment_id] = dict(Emotion=total_eval, Label=label, WavPath=wav_path, Text=file_content[:-1])\n",
    "        else:\n",
    "            # 해당 감정 레이블이 emotions 리스트에 없을 경우 무시\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08e559a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(dictionary, file_name):\n",
    "    json_data = json.dumps(dictionary, ensure_ascii=False)\n",
    "    with open(file_name, 'w', encoding='utf-8') as f:\n",
    "        f.write(json_data)\n",
    "        \n",
    "def json_to_csv(json_file, csv_file):\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    with open(csv_file, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        # Write header\n",
    "        writer.writerow(['ID', 'Emotion', 'Lable', 'WavPath', 'Text'])\n",
    "        \n",
    "        # Write data\n",
    "        for key, value in data.items():\n",
    "            row = [key, value['Emotion'], value['Label'], value['WavPath'], value['Text']]\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcf46ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_final = dict()\n",
    "    test_final = dict()\n",
    "    \n",
    "    annotation_root = f\"./KEMDy19/annotation\"\n",
    "    csv_files = os.listdir(annotation_root)\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        csv_path = annotation_root + '/' + csv_file\n",
    "        dataframe, idx_array = column_extraction(csv_path)\n",
    "\n",
    "        train_indices = idx_array[:int(len(dataframe) * 0.8)]\n",
    "        test_indices = idx_array[int(len(dataframe) * 0.8):]\n",
    "\n",
    "        process_emotion(dataframe, train_final, train_indices)\n",
    "        process_emotion(dataframe, test_final, test_indices)\n",
    "    \n",
    "    save_json(train_final, './train.json')\n",
    "    save_json(test_final, './test.json')\n",
    "\n",
    "    json_to_csv('./train.json', './train.csv')\n",
    "    json_to_csv('./test.json', './test.csv')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e6fcf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etri",
   "language": "python",
   "name": "etri"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
